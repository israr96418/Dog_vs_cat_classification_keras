{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/israr96418/Dog_vs_cat_classification_keras/blob/main/Cat_vs_dog_imageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "44SNIOSw7udM"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lho1SlY9l7b",
        "outputId": "1080b902-600c-4086-eb49-e53e03dfc22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 1.06G/1.06G [00:40<00:00, 31.7MB/s]\n",
            "100% 1.06G/1.06G [00:40<00:00, 28.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QuLkjqXS-P2S"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "myzip_data = zipfile.ZipFile(\"/content/dogs-vs-cats.zip\", \"r\")\n",
        "myzip_data.extractall(\"/content\")\n",
        "myzip_data.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "37BPL_TcC-Dq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, MaxPooling2D, Flatten,BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIhZ2aymEiYB",
        "outputId": "0b017c6c-a261-4946-9961-db4af4ba5511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# create 2 Generator(divide the data into batches)\n",
        "# generator work very well with large data b/z it divide into small batches\n",
        "# if we have 1million of images-->so to pass all images at a time will be very time consuming some time \n",
        "# may be RAM will be not sufficient for this \n",
        "\n",
        "# so thats way we divide into batches ant pass it every batch to process\n",
        "\n",
        "# 3 types of generator\n",
        "  #  1: fit_generator(one for train and another for validation)\n",
        "  #  2:evalute_generator(similar to fit_generator)\n",
        "  #  3:predict_generator\n",
        "\n",
        "train_data =  keras.utils.image_dataset_from_directory(\n",
        "    directory =\"/content/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size =30,\n",
        "    image_size =(256,256)\n",
        "\n",
        ") \n",
        "\n",
        "test_data =  keras.utils.image_dataset_from_directory(\n",
        "    directory =\"/content/test\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size =30,\n",
        "    image_size =(256,256)\n",
        "\n",
        "\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JsvXaK8xJPbZ"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "# As we known that RGB images having every pixel as triplet([0-255,0-255,0-255])\n",
        "# we want to convert into 0-255 every triplet in ever pxel\n",
        "\n",
        "def Normalization(image, label):\n",
        "  image = tf.cast(image/255., tf.float32)\n",
        "  return image,label\n",
        "\n",
        "\n",
        "train_data = train_data.map(Normalization)\n",
        "test_data = test_data.map(Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6KjaxPmW9nC",
        "outputId": "e98c94cf-5ded-47a8-eb4f-85840f654179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               14745728  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,847,297\n",
            "Trainable params: 14,847,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# first Convnet layer\n",
        "model.add(Conv2D(32,kernel_size=(3,3), activation=\"relu\",input_shape=(256,256,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides =2, padding='valid'))\n",
        "\n",
        "# 2nd convnet layer\n",
        "model.add(Conv2D(64,kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides =2, padding='valid'))\n",
        "\n",
        "# 3rd convet layer\n",
        "model.add(Conv2D(128,kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides =2, padding='valid'))\n",
        "\n",
        "# convert any dimensionality into ID\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YFGfeIdqbykk"
      },
      "outputs": [],
      "source": [
        "# comiple your model\n",
        "model.compile(optimizer='adam',loss=\"binary_crossentropy\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd63ENdJcK9p",
        "outputId": "68bd9bfb-4190-4163-a38b-31d1caacb54c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "220/667 [========>.....................] - ETA: 27:33 - loss: 0.6476 - accuracy: 0.6218"
          ]
        }
      ],
      "source": [
        "model.fit(train_data, epochs=20,verbose=1 ,validation_data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3xUwD-NydRV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBXPHrP44gBJ"
      },
      "outputs": [],
      "source": [
        "# As from the above result the val_accuracy very low (means we have to overfitting)\n",
        "# to avoid overfitting and increase val_accuracy we have the following method\n",
        "# 1:L1-regularization\n",
        "# 2:L1-regularization\n",
        "# 3:Dropout layer\n",
        "# 4:Batch_Normalization\n",
        "# 5:data augmentation\n",
        "#6: complex your model-->increase conv2d layer , number of kernal metrices, size of kernal metrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhhumXoAHfjV"
      },
      "outputs": [],
      "source": [
        "from numpy import histogram\n",
        "# I want to draw a graph to visualized the difference train accuracy and validation_accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'],color='red',label='train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Q86P6RIb4t"
      },
      "outputs": [],
      "source": [
        "from numpy import histogram\n",
        "# I want to draw a graph to visualized the difference train accuracy and validation_accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'],color='red',label='train_accuracy')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIoeJwCHI21L"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAe8uaIYJbda"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "test_image = cv2.imread(\"/content/dog2.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCVUDZtTKQ8S"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33Bhj-O-KV_g"
      },
      "outputs": [],
      "source": [
        "test_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yasIsa5QKbI3"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.resize(test_image,(256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFwtuaHnKohg"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6EvX-_kKuzs"
      },
      "outputs": [],
      "source": [
        "test_input_image = test_image.reshape(1,256,256,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVtCwFqyK5vU"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqqxDWWzK_Wq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3g0ebBOc8BHoaa077XW3s",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}